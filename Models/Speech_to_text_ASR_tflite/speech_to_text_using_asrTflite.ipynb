{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b034224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "\n",
    "if 'output.wav' in os.listdir():\n",
    "    os.remove('output.wav')\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e67ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "file = 'output.wav'\n",
    "pygame.init()\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(file)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914bcf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99468448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4446b8ce",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55d63e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf9b9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLite_model = 'lite-model_ASR_TFLite_pre_trained_models_English_1.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82333920",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = 'output.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eff1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, _ = librosa.load(os.path.expanduser(audio), sr=16000, mono=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ff9b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=TFLite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae5d5fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0000\u0000\u0000said \u0000\u0000\u0000ind\u0000ig\u0000\u0000na\u0000\u0000nt \u0000mar\u0000in\u0000\u0000ue\u0000\u0000d \u0000\u0000h\u0000\u0000\u0000\n"
     ]
    }
   ],
   "source": [
    "interpreter.resize_tensor_input(input_details[0][\"index\"], signal.shape)\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.set_tensor(input_details[0][\"index\"], signal)\n",
    "interpreter.set_tensor(\n",
    "    input_details[1][\"index\"],\n",
    "    np.array(0).astype('int32')\n",
    ")\n",
    "interpreter.set_tensor(\n",
    "    input_details[2][\"index\"],\n",
    "    np.zeros([1,2,1,320]).astype('float32')\n",
    ")\n",
    "interpreter.invoke()\n",
    "hyp = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "print(\"\".join([chr(u) for u in hyp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ae90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
